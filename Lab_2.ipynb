{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 2-draft code-upload to LEO.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIhVIbRHDcWL"
      },
      "source": [
        "Send different subsets of input features through the wide or deep paths.\n",
        "\n",
        "\n",
        "\n",
        "* We will send 5 features (features 0 to 4), and 6 through the deep path (features 2 to 7).\n",
        "\n",
        "* 3 features will go through both (features 2, 3 and 4).\n",
        "\n",
        "\n",
        "Then, visualize with TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os"
      ],
      "metadata": {
        "id": "UV7jkKxPG65i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QupQY76UDcWL"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42) # set this seed as the last two digits of your student ID\n",
        "tf.random.set_seed(42) # set this seed as the last two digits of your student ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL8whFKGDcWH"
      },
      "outputs": [],
      "source": [
        "# import california_housing dataset\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "# split dataset\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train) # X_train.shape->(11610, 8).  8 features\n",
        "X_valid = scaler.transform(X_valid)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
      ],
      "metadata": {
        "id": "3XJoxjUYWlTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_logdir = os.path.join(os.curdir, \"my_logs\")"
      ],
      "metadata": {
        "id": "fcWzfV2Fhm5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "run_logdir"
      ],
      "metadata": {
        "id": "XsTW73pOhz6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}